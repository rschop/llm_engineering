{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2751b0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.firecrawl import FireCrawlLoader\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18b55ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "os.environ['FIRECRAWL_API_KEY'] = os.getenv('FIRECRAWL_API_KEY', 'your-key-if-not-using-env')\n",
    "FIRECRAWL_API_KEY = os.getenv('FIRECRAWL_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "616fcba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = FireCrawlLoader(\n",
    "    api_key=FIRECRAWL_API_KEY, url=\"https://firecrawl.dev\", mode=\"scrape\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207fb2b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "Unexpected error during scrape URL: Status code 400. Bad Request - [{'code': 'unrecognized_keys', 'keys': ['params'], 'path': [], 'message': 'Unrecognized key in body -- please review the v1 API documentation for request body changes'}]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m pages = []\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# do some paged operation, e.g.\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# index.upsert(page)\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm_engineering/llms/lib/python3.12/site-packages/langchain_community/document_loaders/firecrawl.py:275\u001b[39m, in \u001b[36mFireCrawlLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[Document]:\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33mscrape\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    274\u001b[39m         firecrawl_docs = [\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfirecrawl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscrape_url\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlegacy_scrape_options_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m         ]\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33mcrawl\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    280\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.url:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm_engineering/llms/lib/python3.12/site-packages/firecrawl/firecrawl.py:586\u001b[39m, in \u001b[36mFirecrawlApp.scrape_url\u001b[39m\u001b[34m(self, url, formats, include_tags, exclude_tags, only_main_content, wait_for, timeout, location, mobile, skip_tls_verification, remove_base64_images, block_ads, proxy, extract, json_options, actions, change_tracking_options, max_age, store_in_cache, **kwargs)\u001b[39m\n\u001b[32m    584\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mFailed to parse Firecrawl response as JSON.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m586\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mscrape URL\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm_engineering/llms/lib/python3.12/site-packages/firecrawl/firecrawl.py:2234\u001b[39m, in \u001b[36mFirecrawlApp._handle_error\u001b[39m\u001b[34m(self, response, action)\u001b[39m\n\u001b[32m   2231\u001b[39m message = \u001b[38;5;28mself\u001b[39m._get_error_message(response.status_code, action, error_message, error_details)\n\u001b[32m   2233\u001b[39m \u001b[38;5;66;03m# Raise an HTTPError with the custom message and attach the response\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2234\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m requests.exceptions.HTTPError(message, response=response)\n",
      "\u001b[31mHTTPError\u001b[39m: Unexpected error during scrape URL: Status code 400. Bad Request - [{'code': 'unrecognized_keys', 'keys': ['params'], 'path': [], 'message': 'Unrecognized key in body -- please review the v1 API documentation for request body changes'}]"
     ]
    }
   ],
   "source": [
    "pages = []\n",
    "for doc in loader.lazy_load():\n",
    "    pages.append(doc)\n",
    "    if len(pages) >= 10:\n",
    "        # do some paged operation, e.g.\n",
    "        # index.upsert(page)\n",
    "\n",
    "        pages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8650663",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "Unexpected error during scrape URL: Status code 400. Bad Request - [{'code': 'unrecognized_keys', 'keys': ['params'], 'path': [], 'message': 'Unrecognized key in body -- please review the v1 API documentation for request body changes'}]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m data = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm_engineering/llms/lib/python3.12/site-packages/langchain_core/document_loaders/base.py:32\u001b[39m, in \u001b[36mBaseLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m     31\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm_engineering/llms/lib/python3.12/site-packages/langchain_community/document_loaders/firecrawl.py:275\u001b[39m, in \u001b[36mFireCrawlLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[Document]:\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33mscrape\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    274\u001b[39m         firecrawl_docs = [\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfirecrawl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscrape_url\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlegacy_scrape_options_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m         ]\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33mcrawl\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    280\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.url:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm_engineering/llms/lib/python3.12/site-packages/firecrawl/firecrawl.py:586\u001b[39m, in \u001b[36mFirecrawlApp.scrape_url\u001b[39m\u001b[34m(self, url, formats, include_tags, exclude_tags, only_main_content, wait_for, timeout, location, mobile, skip_tls_verification, remove_base64_images, block_ads, proxy, extract, json_options, actions, change_tracking_options, max_age, store_in_cache, **kwargs)\u001b[39m\n\u001b[32m    584\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mFailed to parse Firecrawl response as JSON.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m586\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mscrape URL\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm_engineering/llms/lib/python3.12/site-packages/firecrawl/firecrawl.py:2234\u001b[39m, in \u001b[36mFirecrawlApp._handle_error\u001b[39m\u001b[34m(self, response, action)\u001b[39m\n\u001b[32m   2231\u001b[39m message = \u001b[38;5;28mself\u001b[39m._get_error_message(response.status_code, action, error_message, error_details)\n\u001b[32m   2233\u001b[39m \u001b[38;5;66;03m# Raise an HTTPError with the custom message and attach the response\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2234\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m requests.exceptions.HTTPError(message, response=response)\n",
      "\u001b[31mHTTPError\u001b[39m: Unexpected error during scrape URL: Status code 400. Bad Request - [{'code': 'unrecognized_keys', 'keys': ['params'], 'path': [], 'message': 'Unrecognized key in body -- please review the v1 API documentation for request body changes'}]"
     ]
    }
   ],
   "source": [
    "data = loader.load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
